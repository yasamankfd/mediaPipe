<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Frontal Face Detection with Occlusion</title>
    <style>
      body {
        margin: 0;
        overflow: hidden;
        font-family: Arial, sans-serif;
      }

      #videoElement,
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        object-fit: cover;
      }

      #status {
        position: absolute;
        top: 10px;
        left: 10px;
        background: rgba(0, 0, 0, 0.7);
        color: white;
        padding: 10px;
        border-radius: 5px;
        font-size: 18px;
        z-index: 10;
      }

      #saveButton {
        position: absolute;
        top: 60px;
        left: 10px;
        background: #4caf50;
        color: white;
        padding: 10px 16px;
        border: none;
        border-radius: 5px;
        font-size: 16px;
        cursor: pointer;
        z-index: 10;
      }

      #saveButton:hover {
        background: #45a049;
      }
    </style>
  </head>
  <body>
    <video id="videoElement" autoplay muted playsinline></video>
    <canvas class="output_canvas" id="output"></canvas>
    <div id="status">â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„...</div>
    <button id="saveButton">ğŸ“¸ Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ±</button>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <script>
      const videoElement = document.getElementById("videoElement");
      const canvasElement = document.getElementById("output");
      const canvasCtx = canvasElement.getContext("2d");
      const statusText = document.getElementById("status");

      let lastLandmarks = null;
      let lastIsFrontal = false;
      let lastIsOccluded = false;

      let recentStatuses = [];
      const STATUS_WINDOW = 5;

      function stableStatus(newStatus) {
        recentStatuses.push(newStatus);
        if (recentStatuses.length > STATUS_WINDOW) {
          recentStatuses.shift();
        }

        const counts = {};
        for (const s of recentStatuses) {
          counts[s] = (counts[s] || 0) + 1;
        }

        let topStatus = newStatus;
        let maxCount = 0;
        for (const [status, count] of Object.entries(counts)) {
          if (count > maxCount) {
            topStatus = status;
            maxCount = count;
          }
        }

        return topStatus;
      }

      document.getElementById("saveButton").addEventListener("click", () => {
        if (!lastLandmarks || !lastIsFrontal || lastIsOccluded) {
          alert("Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ú†Ù‡Ø±Ù‡ ÙˆØ§Ø¶Ø­ Ùˆ Ø¨Ø¯ÙˆÙ† Ø§Ù†Ø³Ø¯Ø§Ø¯ Ø§Ø³Øª.");
          return;
        }

        const link = document.createElement("a");
        link.download = "face_snapshot.png";
        link.href = canvasElement.toDataURL("image/png");
        link.click();
      });

      function isFrontal(landmarks) {
        const leftEye = landmarks[33];
        const rightEye = landmarks[263];
        const noseTip = landmarks[1];
        const chin = landmarks[152];

        const midX = (leftEye.x + rightEye.x) / 2;
        const horizOffset = Math.abs(noseTip.x - midX);
        const verticalRatio = Math.abs(chin.y - noseTip.y);

        const maxHorizOffset = 0.035;
        const minVerticalLength = 0.08;

        return (
          horizOffset < maxHorizOffset && verticalRatio > minVerticalLength
        );
      }

      let referenceRatios = null;
      const ratioPairs = [
        [33, 263],
        [133, 362],
        [61, 291],
        [13, 152],
        [1, 199],
        [33, 61],
        [263, 291],
        [1, 13],
        [168, 8],
        [234, 454],
        [10, 152],
        [67, 297],
        [0, 17],
        [17, 36],
        [78, 308],
      ];

      function computeRatios(landmarks) {
        return ratioPairs.map(([i, j]) => {
          const dx = landmarks[i].x - landmarks[j].x;
          const dy = landmarks[i].y - landmarks[j].y;
          return Math.sqrt(dx * dx + dy * dy);
        });
      }

      function isOccluded(landmarks) {
        const currentRatios = computeRatios(landmarks);
        if (!referenceRatios) {
          referenceRatios = currentRatios;
          return false;
        }

        let deviationCount = 0;
        for (let i = 0; i < ratioPairs.length; i++) {
          const ref = referenceRatios[i];
          const curr = currentRatios[i];
          const diff = Math.abs(curr - ref) / ref;

          if (diff > 0.1) {
            deviationCount++;
          }
        }

        return deviationCount >= 1;
      }

      const faceMesh = new FaceMesh({
        locateFile: (file) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
      });

      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: true,
        minDetectionConfidence: 0.9,
        minTrackingConfidence: 0.6,
      });

      faceMesh.onResults((results) => {
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;

        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        canvasCtx.drawImage(
          results.image,
          0,
          0,
          canvasElement.width,
          canvasElement.height
        );

        if (results.multiFaceLandmarks.length === 0) {
          statusText.textContent = stableStatus("âŒ Ú†Ù‡Ø±Ù‡ Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯");
        } else {
          const landmarks = results.multiFaceLandmarks[0];
          lastLandmarks = landmarks;
          lastIsFrontal = isFrontal(landmarks);
          lastIsOccluded = isOccluded(landmarks);

          let status = "";

          if (!lastIsFrontal) {
            status = "âš ï¸ Ú†Ù‡Ø±Ù‡ Ø±ÙˆØ¨Ø±ÙˆÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù†ÛŒØ³Øª";
          } else if (lastIsOccluded) {
            status = "âš ï¸ Ú†Ù‡Ø±Ù‡ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª";
          } else {
            status = "âœ… Ú†Ù‡Ø±Ù‡ ØµØ­ÛŒØ­ Ø§Ø³Øª";
          }

          statusText.textContent = stableStatus(status);
        }

        canvasCtx.restore();
      });

      const camera = new Camera(videoElement, {
        onFrame: async () => {
          await faceMesh.send({ image: videoElement });
        },
        width: 640,
        height: 480,
      });

      camera.start().then(() => {
        statusText.textContent = "ğŸ§  Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡...";
      });
    </script>
  </body>
</html>
